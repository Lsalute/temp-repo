# Exploration 4
인공지능 작사가 만들기


### [ 절차 ]
1. 데이터 다듬기
2. 학습
3. 평가
4. 작사하기

### 시퀀스 (Sequence)
[참고자료](https://python.bakyeono.net/chapter-5-2.html)   
시퀀스 데이터는 나열된 데이터를 의미하므로, 각 요소들이 동일한 속성을 띌 필요가 없으며, 어떤 기준에 따라 정렬되어 있지 않아도 된다.

### 순환신경망(RNN)
어떤 문법적인 원리를 통해서가 아니고, 수많은 글을 읽게 함으로써 `알바생이` , `커피를`, 그다음이 `만든다` 라는 사실을 알게 한다.    
그런 이유에서 많은 데이터가 곧 좋은 결과를 만들어낸다.   
이 방식을 가장 잘 처리하는 인공지능 중 하나가 **순환신경망(RNN)** 이다.   
[참고자료](https://wikidocs.net/22886)

![image](https://user-images.githubusercontent.com/25050210/126717787-d89b2ce8-84e1-43d6-bef1-fb9d50037a44.png)

`<start>` 라는 특수한 토큰을 맨 앞에 추가해 `<start>` 를 입력으로 받은 순환신경망은 다음 단어로 나는 을 생성하고, 생성한 단어를 다시 입력으로 사용한다.
순환신경망이라 이름이 붙은 이유이다. `커피를 만든다` 까지 생성하고 나면, 인공지능이 다 만들었다는 사인으로 `<end>` 라는 특수한 토큰을 생성한다.
우리는 `<start>` 가 문장의 시작에 더해진 입력 데이터(문제지)와, `<end>` 가 문장의 끝에 더해진 출력 데이터(답안지)가 필요하며,    
이는 문장 데이터만 있으면 만들어낼 수 있다는 것을 알 수 있다.

### 언어 모델 (Language Model)
`알바생이`, `커피를`, `만든다` 를 순차적으로 생성할 때, `커피를` 다음이 `만든다` 인 것은 쉽게 알 수 있다.    
하지만 `알바생이` 다음이 `커피를` 인 것은 조금 억지처럼 느껴질 수 있다. 실제로 동작하는 방식도, `커피를` 을 만드는 것은 순전히 운이며, 우리가 의도한다고 나오는 것이 아니다.

`알바생`이 `커피를` 다음에 `만든다` 가 나올 확률을 P(만든다 | 알바생이, 커피를) 이라고 치자면,    
이 확률은 `알바생` 뒤에 `커피를` 가 나올 확률인 P(커피를 | 알바생이) 보다는 높게 나올 것입니다.    
어떤 문구 뒤에 다음 단어가 나올 확률이 높다는 것은 그 단어가 나오는 것이 보다 자연스럽다는 뜻이 되며,    
`알바생` 뒤에 `커피를`이 나오는 것이 자연스럽지 않다는 뜻으로 들릴테지만 그것은 아니다.   
`알바생` 뒤에 올 수 있는 자연스러운 단어의 경우의 수가 워낙 많다 보니 불확실성이 높을 뿐이다.

n−1개의 단어 시퀀스 w_1, \cdots, w_{n-1}w 1 ,⋯,w n−1 가 주어졌을 때, nn번째 단어 w_nw n으로 무엇이 올지를 예측하는 확률 모델을 언어 모델(Language Model) 이라고 부릅니다. 파라미터 \thetaθ로 모델링 하는 언어 모델을 다음과 같이 표현할 수 있습니다.

<img width="208" alt="Screen Shot 2021-07-23 at 7 55 03 AM" src="https://user-images.githubusercontent.com/25050210/126719108-0621ae69-2f2f-4064-9cea-82dea8774c69.png">

ex) 문장생성기(GPT-2, GPT-3)

### 토근화
텍스트 분류 모델에서 많이 본 것처럼 텍스트 생성 모델에도 단어 사전을 만들게 되며, 문장을 일정한 기준으로 쪼개야한다.   
그 과정을 **토큰화(Tokenize)** 라고 한다.
자연어처리 분야에서 모델의 입력이 되는 문장을 **소스 문장(Source Sentence)** , 정답 역할을 하게 될 모델의 출력 문장을 **타겟 문장(Target Sentence)** 라고 관례적으로 부르며,    
각각 X_train, y_train 에 해당한다고 생각하면 된다.

## tensorflow 텐서플로우
자연어 처리를 위한 여러 가지 모듈을 제공한다.    
이 예제에서 활용하게 될 `tf.keras.preprocessing.text.Tokenizer` 패키지는 정제된 데이터를 토큰화하고,    
단어 사전(vocabulary 또는 dictionary라고 칭함)을 만들어주며, 데이터를 숫자로 변환까지 한번에 해결해주며,    
이 과정을 벡터화(vectorize) 라 하며, 숫자로 변환된 데이터를 텐서(tensor) 라고 칭한다.    
우리가 사용하는 텐서플로우로 만든 모델의 입출력 데이터는 실제로는 모두 이런 텐서로 변환되어 처리된다.   
[Tensor의 개념](https://rekt77.tistory.com/102)

### 데이터셋을 생성하기 위한 과정 - 전처리
- 정규표현식을 이용한 corpus 생성
- `tf.keras.preprocessing.text.Tokenizer`를 이용해 `corpus`를 텐서로 변환
- `tf.data.Dataset.from_tensor_slices()`를 이용해 `corpus` 텐서를 `tf.data.Dataset`객체로 변환

나머지 내용은 `.ipynb`에 들어가서 자세히 보기.

