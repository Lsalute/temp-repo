{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import PIL, numpy, os, glob \n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "\n",
    "print(\"import PIL, numpy, os, glob \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일들 unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip rock_scissor_paper.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip test.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train image resize\n",
    "학습할 데이터를 28x28사이즈로 resize시켜준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위, 바위, 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = \"./rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = \"./rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = \"./rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test image resize\n",
    "test 이미지를 28x28사이즈로  resize시켜준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "test 가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "test 바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "test 보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = \"./test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"test 가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = \"./test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"test 바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = \"./test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"test 보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가위: 0, 바위: 1, 보: 2 로 라벨링해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n",
      "x_train_norm: (300, 28, 28, 3) \n"
     ]
    }
   ],
   "source": [
    "# 이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성\n",
    "def load_data(img_path, number_of_data=300): \n",
    "    img_size=28 # resize할 크기\n",
    "    color=3 # 색상은 3, 흑백은 1\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = \"./rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"x_train_norm: {} \".format(x_train_norm.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[40])\n",
    "print('라벨: ', y_train[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test데이터 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n",
      "x_test_norm : (300, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = \"./test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "print(\"x_test_norm : {}\".format(x_test_norm.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_108 (Conv2D)          (None, 26, 26, 45)        1260      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_108 (MaxPoolin (None, 13, 13, 45)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 11, 11, 57)        23142     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_109 (MaxPoolin (None, 5, 5, 57)          0         \n",
      "_________________________________________________________________\n",
      "flatten_54 (Flatten)         (None, 1425)              0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 50)                71300     \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 95,855\n",
      "Trainable params: 95,855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "n_channel_1=45\n",
    "n_channel_2=57\n",
    "n_dense=50\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3))) # 컬러 이미지므로 3\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 가위, 바위, 보이므로 클래스 3개\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 1s 17ms/step - loss: 1.1121 - accuracy: 0.3300\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0838 - accuracy: 0.3633\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.0491 - accuracy: 0.5067\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.0102 - accuracy: 0.5300\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9492 - accuracy: 0.5467\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9312 - accuracy: 0.5633\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8713 - accuracy: 0.5933\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8037 - accuracy: 0.6367\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7545 - accuracy: 0.7000\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6967 - accuracy: 0.6833\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6501 - accuracy: 0.7467\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5595 - accuracy: 0.8367\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5165 - accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5105 - accuracy: 0.8033\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4210 - accuracy: 0.8633\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.4358 - accuracy: 0.8200\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.4045 - accuracy: 0.8433\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.3282 - accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.2933 - accuracy: 0.9233\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2701 - accuracy: 0.9100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f918a42a810>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터로 성능을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.2031 - accuracy: 0.6400\n",
      "test_loss: 1.2031381130218506 \n",
      "test_accuracy: 0.6399999856948853\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
