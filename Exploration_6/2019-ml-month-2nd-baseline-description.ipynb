{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38bfbd5ada16035c96bb21265c51de80361f17b4"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "train_data_path = join(data_dir, 'train.csv')\n",
    "sub_data_path = join(data_dir, 'test.csv')      # 테스트, 즉 submission 시 사용할 데이터 경로\n",
    "\n",
    "print(train_data_path)\n",
    "print(sub_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[python os.path](https://docs.python.org/3/library/os.path.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f0d3320a32138c92ed7b0629a57bd5a719603b0"
   },
   "source": [
    "## 1. 데이터 살펴보기\n",
    "pandas의 read_csv 함수를 사용해 데이터를 읽어오고, 각 변수들이 나타내는 의미를 살펴보겠습니다.\n",
    "1. ID : 집을 구분하는 번호\n",
    "2. date : 집을 구매한 날짜\n",
    "3. price : 타겟 변수인 집의 가격\n",
    "4. bedrooms : 침실의 수\n",
    "5. bathrooms : 침실당 화장실 개수\n",
    "6. sqft_living : 주거 공간의 평방 피트\n",
    "7. sqft_lot : 부지의 평방 피트\n",
    "8. floors : 집의 층 수\n",
    "9. waterfront : 집의 전방에 강이 흐르는지 유무 (a.k.a. 리버뷰)\n",
    "10. view : 집이 얼마나 좋아 보이는지의 정도\n",
    "11. condition : 집의 전반적인 상태\n",
    "12. grade : King County grading 시스템 기준으로 매긴 집의 등급\n",
    "13. sqft_above : 지하실을 제외한 평방 피트\n",
    "14. sqft_basement : 지하실의 평방 피트\n",
    "15. yr_built : 집을 지은 년도\n",
    "16. yr_renovated : 집을 재건축한 년도\n",
    "17. zipcode : 우편번호\n",
    "18. lat : 위도\n",
    "19. long : 경도\n",
    "20. sqft_living15 : 2015년 기준 주거 공간의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)\n",
    "21. sqft_lot15 : 2015년 기준 부지의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df5891d33b4d5f08c0011b712f8796417564ec17"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(train_data_path)\n",
    "sub = pd.read_csv(sub_data_path)\n",
    "print('train data dim : {}'.format(data.shape))\n",
    "print('sub data dim : {}'.format(sub.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 데이터에서 라벨 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "251c25b4f9c89db8b6643448369198e94437cfd7"
   },
   "outputs": [],
   "source": [
    "y = data['price']\n",
    "\n",
    "del data['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 데이터와 테스트 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc5d87141207fedeb521461bd0d0cc23c0c594f2"
   },
   "outputs": [],
   "source": [
    "train_len = len(data)\n",
    "data = pd.concat((data, sub), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96537247c40a4932e581a5c681d73348f6b3936b"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "39cc64c64be8d6f2ebd5c7c2523973bbcfb29c94"
   },
   "source": [
    "## 2. 간단한 전처리 \n",
    "각 변수들에 대해 결측 유무를 확인하고, 분포를 확인해보면서 간단하게 전처리를 하겠습니다.\n",
    "### 결측치 확인\n",
    "먼저 데이터에 결측치가 있는지를 확인하겠습니다.<br>\n",
    "missingno 라이브러리의 matrix 함수를 사용하면, 데이터의 결측 상태를 시각화를 통해 살펴볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e8ce87398995d2f86fc5cb7b15294f46ece7801"
   },
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a89a32c9e3491c45bf3188d22a40a211e3850d66"
   },
   "source": [
    "모든 변수에 결측치가 없는 것으로 보이지만, 혹시 모르니 확실하게 살펴보겠습니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터 고급 인덱싱](https://datascienceschool.net/01%20python/04.03%20%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%94%84%EB%A0%88%EC%9E%84%20%EA%B3%A0%EA%B8%89%20%EC%9D%B8%EB%8D%B1%EC%8B%B1.html?highlight=%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%94%84%EB%A0%88%EC%9E%84%20%EA%B3%A0%EA%B8%89%20%EC%9D%B8%EB%8D%B1%EC%8B%B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6f406f14203d742ff26da3454935aa05c8364922"
   },
   "outputs": [],
   "source": [
    "for c in data.columns:\n",
    "    print('{} : {}'.format(c, len(data.loc[pd.isnull(data[c]), c].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94ad23d7a91a68c1be7fcd4953013f5353541545"
   },
   "source": [
    "### id, date 변수 정리\n",
    "id 변수는 모델이 집값을 예측하는데 도움을 주지 않으므로 제거합니다.<br>\n",
    "date 변수는 연월일시간으로 값을 가지고 있는데, 연월만 고려하는 범주형 변수로 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c48e1c16ec0725128286a0d524faff9bd725ed4"
   },
   "outputs": [],
   "source": [
    "sub_id = data['id'][train_len:]\n",
    "del data['id']\n",
    "data['date'] = data['date'].apply(lambda x : str(x[:6])).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "200283a8d82a4f8c1951013961b5af3f91cc8be1"
   },
   "source": [
    "### 각 변수들의 분포 확인\n",
    "한쪽으로 치우친 분포는 모델이 결과를 예측하기에 좋지 않은 영향을 미치므로 다듬어줄 필요가 있습니다.   \n",
    "[seaborn sns.kdeplot](https://seaborn.pydata.org/generated/seaborn.kdeplot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2aa785314a8bb8d9f84bbc17cb55e38c564a8f3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(9, 2, figsize=(12, 50))   # 가로스크롤 때문에 그래프 확인이 불편하다면 figsize의 x값을 조절해 보세요. \n",
    "\n",
    "# id 변수(count==0인 경우)는 제외하고 분포를 확인합니다.\n",
    "count = 1\n",
    "columns = data.columns\n",
    "for row in range(9):\n",
    "    for col in range(2):\n",
    "        sns.kdeplot(data[columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(columns[count], fontsize=15)\n",
    "        count += 1\n",
    "        if count == 19 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b377cd53ae25ab16f09d303c5cf0019bc004f465"
   },
   "source": [
    "price, bedrooms, sqft_living, sqft_lot, sqft_above, sqft_basement 변수가 한쪽으로 치우친 경향을 보였습니다.<br>\n",
    "log-scaling을 통해 데이터 분포를 정규분포에 가깝게 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24bb873fdfcdf1511b75aff69456b49d36f8f637"
   },
   "outputs": [],
   "source": [
    "skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement']\n",
    "\n",
    "for c in skew_columns:\n",
    "    data[c] = np.log1p(data[c].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "876da0a04810168164a97239fc809ea38b277cdb"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "count = 0\n",
    "for row in range(3):\n",
    "    for col in range(2):\n",
    "        if count == 5:\n",
    "            break\n",
    "        sns.kdeplot(data[skew_columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(skew_columns[count], fontsize=15)\n",
    "        count+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5923d97d51ae10050473c02eb8d56afa6d3e7567"
   },
   "source": [
    "어느정도 치우침이 줄어든 분포를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4d31773ba934e8b48564fb8207df9e574b3a195"
   },
   "outputs": [],
   "source": [
    "sub = data.iloc[train_len:, :]\n",
    "x = data.iloc[:train_len, :]\n",
    "\n",
    "print(sub.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4afe676edcf34f694c95c3f0e6287d13edaee26"
   },
   "source": [
    "## 3. 모델링\n",
    "### Average Blending\n",
    "여러가지 모델의 결과를 산술 평균을 통해 Blending 모델을 만들겠다.   \n",
    "Baseline 커널에서는 여러 가지 모델을 함께 사용해서 결과를 섞는, 블렌딩(blending) 이라는 기법을 활용한다.\n",
    "블렌딩은 앙상블 기법이라고 하기도 한다.\n",
    "\n",
    "[Ensemble learning](https://subinium.github.io/introduction-to-ensemble-1/#:~:text=%EC%95%99%EC%83%81%EB%B8%94(Ensemble)%20%ED%95%99%EC%8A%B5%EC%9D%80%20%EC%97%AC%EB%9F%AC,%EB%A5%BC%20%EA%B0%80%EC%A7%80%EA%B3%A0%20%EC%9D%B4%ED%95%B4%ED%95%98%EB%A9%B4%20%EC%A2%8B%EC%8A%B5%EB%8B%88%EB%8B%A4.)   \n",
    "[Ensemble Guide](https://gentlej90.tistory.com/73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "296645421a135dc34c45f822ce73d31eeb107bdc"
   },
   "outputs": [],
   "source": [
    "# boosting 계열 모델 3가지\n",
    "gboost = GradientBoostingRegressor(random_state=2019)\n",
    "xgboost = xgb.XGBRegressor(random_state=2019)\n",
    "lightgbm = lgb.LGBMRegressor(random_state=2019)\n",
    "\n",
    "models = [{'model':gboost, 'name':'GradientBoosting'}, {'model':xgboost, 'name':'XGBoost'},\n",
    "          {'model':lightgbm, 'name':'LightGBM'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "578896883c6b8c6a2c5785a93121b62506b22a21"
   },
   "source": [
    "### Cross Validation\n",
    "교차 검증을 통해 모델의 성능을 간단히 평가하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b48689d7989107ea3524126c330e2225a58e4d3"
   },
   "outputs": [],
   "source": [
    "def get_cv_score(models):\n",
    "    kfold = KFold(n_splits=5, random_state=2019).get_n_splits(x.values)\n",
    "    for m in models:\n",
    "        print(\"Model {} CV score : {:.4f}\".format(m['name'], np.mean(cross_val_score(m['model'], x.values, y)), \n",
    "                                             kf=kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53ea586dd0b4fe5481db7bfb9cbcb998ef88b648"
   },
   "outputs": [],
   "source": [
    "get_cv_score(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a26c1d6aa9b779077f84ec60b7f29385fc2e058b"
   },
   "source": [
    "### Make Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1004d9b01d1c3068d9e8a81f263315435478e591"
   },
   "source": [
    "회귀 모델의 경우에는 cross_val_score 함수가 R<sup>2</sup>를 반환합니다.<br>\n",
    "R<sup>2</sup> 값이 1에 가까울수록 모델이 데이터를 잘 표현함을 나타냅니다. 3개 트리 모델이 상당히 훈련 데이터에 대해 괜찮은 성능을 보여주고 있습니다.<br> 훈련 데이터셋으로 3개 모델을 학습시키고, Average Blending을 통해 제출 결과를 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "20af2394b94bdc14fe1b23688874fadbf1c2846a"
   },
   "outputs": [],
   "source": [
    "def AveragingBlending(models, x, y, sub_x):\n",
    "    for m in models : \n",
    "        m['model'].fit(x.values, y)\n",
    "    \n",
    "    predictions = np.column_stack([\n",
    "        m['model'].predict(sub_x.values) for m in models\n",
    "    ])\n",
    "    return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7bdb1c740291e6d1721cf02cd3f59bb79153c87"
   },
   "outputs": [],
   "source": [
    "y_pred = AveragingBlending(models, x, y, sub)\n",
    "print(len(y_pred))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9c9d0901bcf5e4754b40a6922292c04951b81bae"
   },
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "submission_path = join(data_dir, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\n",
    "    'id' : sub_id, \n",
    "    'price' : y_pred\n",
    "})\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2047d6ee5f5da05e5463d51d1fbbe82a94732a48"
   },
   "outputs": [],
   "source": [
    "my_submission_path = join(data_dir, 'submission.csv')\n",
    "result.to_csv(my_submission_path, index=False)\n",
    "\n",
    "print(my_submission_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랭킹 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "train_data_path = join(data_dir, 'train.csv')\n",
    "test_data_path = join(data_dir, 'test.csv') \n",
    "\n",
    "train = pd.read_csv(train_data_path)\n",
    "test = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline 커널이 했던 것과 달리, 우리는 int, 즉 정수형 데이터로 처리해보겠습니다.    \n",
    "이렇게 하면 모델이 date도 예측을 위한 특성으로 활용할 수 있을 것이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = train['date'].apply(lambda i: i[:6]).astype(int)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y 변수에 `price`를 넣어두고, train에서는 삭제한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['price']\n",
    "del train['price']\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`id` 컬럼을 삭제하는 것까지 하면 기본적인 전처리는 모두 마무리된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['id']\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test에 우리가 맞추어야 할 타겟 데이터인 `price`는 없으니 훈련 데이터셋과는 다르게 price에 대한 처리는 해주지 않아도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['date'] = test['date'].apply(lambda i: i[:6]).astype(int)\n",
    "\n",
    "del test['id']\n",
    "\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타겟 데이터인 y를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y는 `np.log1p()` 함수를 통해 로그 변환을 해주고, 나중에 모델이 값을 예측한 후에 다시 `np.exp1m()`을 활용해서 되돌려놓는다.      \n",
    "`np.exp1m()`은 `np.log1p()`과는 반대로 각 원소 x마다 exp(x)-1의 값을 반환해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(y)\n",
    "sns.kdeplot(y)\n",
    "plt.show()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info() 함수로 전체 데이터의 자료형을 한눈에 확인하자\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과정들을 함수로 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋을 훈련(train) 데이터셋과 검증(test) 데이터셋으로 나누기 위한 train_test_split 함수와,    \n",
    "RMSE 점수를 계산하기 위한 mean_squared_error를 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 가지 주의해야 할 것은, y_test나 y_pred는 위에서 `np.log1p()`로 변환이 된 값이기 때문에    \n",
    "원래 데이터의 단위에 맞게 되돌리기 위해 `np.expm1()`을 추가해야 한다.   \n",
    "exp로 다시 변환해서 `mean_squared_error`를 계산한 값에 `np.sqrt`를 취하면 RMSE 값을 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### models라는 리스트에 넣어준다.\n",
    "random_state=2021\n",
    "\n",
    "gboost = GradientBoostingRegressor(random_state=random_state)\n",
    "xgboost = XGBRegressor(random_state=random_state)\n",
    "lightgbm = LGBMRegressor(random_state=random_state)\n",
    "rdforest = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "models = [gboost, xgboost, lightgbm, rdforest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 모델의 이름은 다음과 같이 클래스의 `__name__` 속성에 접근해서 얻을 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "\n",
    "for model in models:\n",
    "    # 모델 이름 획득\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # train, test 데이터셋 분리 - 여기에도 random_state를 고정합니다. \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, y, random_state=random_state, test_size=0.2)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 예측\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 예측 결과의 rmse값 저장\n",
    "    df[model_name] = rmse(y_test, y_pred)\n",
    "    \n",
    "    # data frame에 저장\n",
    "    score_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
    "    \n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 과정을 `get_scores(models, train, y)` 함수로 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(models, train, y):\n",
    "    # 답안 작성\n",
    "    df = {}\n",
    "    \n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(train, y, random_state=random_state, test_size=0.2)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        df[model_name] = rmse(y_test, y_pred)\n",
    "        score_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
    "    \n",
    "    return score_df\n",
    "\n",
    "get_scores(models, train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그리드 탐색을 이용한 하이퍼 파라미터 튜닝\n",
    "- 그리드 탐색(grid search)은 사람이 먼저 탐색할 하이퍼 파라미터의 값들을 정해두고,    \\\n",
    "그 값들로 만들어질 수 있는 모든 조합을 탐색한다. 특정 값에 대한 하이퍼 파라미터 조합을 모두 탐색하고자 할 때 유용하다.\n",
    "- 랜덤 탐색(random search)은 사람이 탐색할 하이퍼 파라미터의 공간만 정해두고, 그 안에서 랜덤으로 조합을 선택해서 탐색하는 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV`에 입력되는 인자들.\n",
    "- param_grid : 탐색할 파라미터의 종류 (딕셔너리로 입력)\n",
    "- scoring : 모델의 성능을 평가할 지표\n",
    "- cv : cross validation을 수행하기 위해 train 데이터셋을 나누는 조각의 개수\n",
    "- verbose : 그리드 탐색을 진행하면서 진행 과정을 출력해서 보여줄 메세지의 양 (숫자가 클수록 더 많은 메세지를 출력합니다.)\n",
    "- n_jobs : 그리드 탐색을 진행하면서 사용할 CPU의 개수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [1, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(model, param_grid=param_grid, \\\n",
    "                        scoring='neg_mean_squared_error', \\\n",
    "                        cv=5, verbose=1, n_jobs=5)\n",
    "\n",
    "grid_model.fit(train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실험에 대한 결과는 다음과 같이 `grid_model.cv_results_`안에 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파라미터 조합은 위 딕셔너리 중 `params`에,    \n",
    "각각에 대한 테스트 점수는 `mean_test_score`에 저장되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = grid_model.cv_results_['params']\n",
    "score = grid_model.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(params)\n",
    "results['score'] = score\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`neg_mean_squared_error`를 사용했기 때문에 점수가 음수로 나온다.    \n",
    "음수로 된 MSE였으니, -1을 곱해주고 `np.sqrt`로 루트 연산을 해주면 RMSE 점수를 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['RMSE'] = np.sqrt(-1 * results['score'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컬럼의 이름을 RMSLE로 변환해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.rename(columns={'RMSE': 'RMSLE'})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 표를 `RMSLE`가 낮은 순서대로 정렬해준다.\n",
    "results.sort_values(\"RMSLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 과정을 함수로 만들어보자.\n",
    "1. GridSearchCV 모델로 `model`을 초기화한다.\n",
    "2. 모델을 fitting 한다.\n",
    "3. params, score에 각 조합에 대한 결과를 저장한다.\n",
    "4. 데이터 프레임을 생성하고, RMSLE 값을 추가한 후 점수가 높은 순서로 정렬한 `results`를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5):\n",
    "    grid_model = GridSearchCV(model, param_grid=param_grid, \\\n",
    "                        scoring='neg_mean_squared_error', \\\n",
    "                        cv=5, verbose=verbose, n_jobs=n_jobs)\n",
    "    grid_model.fit(train, y)\n",
    "    \n",
    "    params = grid_model.cv_results_['params']\n",
    "    score = grid_model.cv_results_['mean_test_score']\n",
    "    \n",
    "    results = pd.DataFrame(params)\n",
    "    results['score'] = score\n",
    "    \n",
    "    results['RMSLE'] = np.sqrt(-1 * results['score'])\n",
    "    results = results.sort_values(\"RMSLE\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험을 통해 좋은 결과를 내는 모델을 찾아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [1, 10],\n",
    "}\n",
    "\n",
    "model = LGBMRegressor(random_state=random_state)\n",
    "my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 표를 보면 가장 좋은 조합은 `max_depth=10`, `n_estimators=100` 이다.   \n",
    "해당 모델로 학습을 해서 예측값인 `submission.csv` 파일을 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(max_depth=10, n_estimators=100, random_state=random_state)\n",
    "model.fit(train, y)\n",
    "prediction = model.predict(test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 결과에 `np.expm1()`을 씌워서 다시 원래 스케일로 되돌리자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.expm1(prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "submission_path = join(data_dir, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['price'] = prediction\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, 'lgbm', '0.164399')\n",
    "submission.to_csv(submission_csv_path, index=False)\n",
    "print(submission_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 과정을 함수로 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(model, train, y, test, model_name, rmsle):\n",
    "    # 모델을 `train`, `y`로 학습\n",
    "    model.fit(train, y)\n",
    "    # `test`에 대해 예측\n",
    "    prediction = model.predict(test)\n",
    "    # 예측값을 `np.expm1`으로 변환\n",
    "    prediction = np.expm1(prediction)\n",
    "    \n",
    "    # sample_submission.csv을 불러옴\n",
    "    data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "    submission_path = join(data_dir, 'sample_submission.csv')\n",
    "    submission = pd.read_csv(submission_path)\n",
    "    \n",
    "    # prediction값을 테이블에 붙인후 `submission_model_name_RMSLE_100000.csv`형태의 이름으로 저장\n",
    "    submission['price'] = prediction\n",
    "    submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, model_name, rmsle)\n",
    "    submission.to_csv(submission_csv_path, index=False)\n",
    "    print(\"{} saved.\".format(submission_csv_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(model, train, y, test, 'lgbm', rmsle='0.0168')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
